{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/imsumin018/daily-code-snippet/blob/main/StudySNN_withMNIST_tutorial_5_neuromorphic_datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "47d5313e-c29d-4581-a9c7-a45122337069",
      "metadata": {
        "id": "47d5313e-c29d-4581-a9c7-a45122337069"
      },
      "source": [
        "[<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/snntorch_alpha_w.png?raw=true' width=\"300\">](https://github.com/jeshraghian/snntorch/)\n",
        "\n",
        "# Quickstart with snnTorch\n",
        "### By Jason K. Eshraghian (www.jasoneshraghian.com)\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/jeshraghian/snntorch/blob/master/examples/quickstart.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "[<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/GitHub-Mark-Light-120px-plus.png?raw=true' width=\"28\">](https://github.com/jeshraghian/snntorch/) [<img src='https://github.com/jeshraghian/snntorch/blob/master/docs/_static/img/GitHub_Logo_White.png?raw=true' width=\"80\">](https://github.com/jeshraghian/snntorch/)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "oll2NNFeG1NG",
      "metadata": {
        "id": "oll2NNFeG1NG"
      },
      "source": [
        "For a comprehensive overview on how SNNs work, and what is going on under the hood, [then you might be interested in the snnTorch tutorial series available here.](https://snntorch.readthedocs.io/en/latest/tutorials/index.html)\n",
        "The snnTorch tutorial series is based on the following paper. If you find these resources or code useful in your work, please consider citing the following source:\n",
        "\n",
        "> <cite> [Jason K. Eshraghian, Max Ward, Emre Neftci, Xinxin Wang, Gregor Lenz, Girish Dwivedi, Mohammed Bennamoun, Doo Seok Jeong, and Wei D. Lu. \"Training Spiking Neural Networks Using Lessons From Deep Learning\". arXiv preprint arXiv:2109.12894, September 2021.](https://arxiv.org/abs/2109.12894) </cite>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "hDnIEHOKB8LD",
      "metadata": {
        "id": "hDnIEHOKB8LD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acd562d8-cfbb-4c45-e223-af8e14109ac3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/109.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.0/109.0 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install snntorch --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "WL487gZW1Agy",
      "metadata": {
        "id": "WL487gZW1Agy"
      },
      "outputs": [],
      "source": [
        "import torch, torch.nn as nn\n",
        "import snntorch as snn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "EYf13Gtx1OCj",
      "metadata": {
        "id": "EYf13Gtx1OCj"
      },
      "source": [
        "## DataLoading\n",
        "Define variables for dataloading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "eo4T5MC21hgD",
      "metadata": {
        "id": "eo4T5MC21hgD"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "data_path='/data/mnist'\n",
        "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "myFKqNx11qYS",
      "metadata": {
        "id": "myFKqNx11qYS"
      },
      "source": [
        "Load MNIST dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "3GdglZjK04cb",
      "metadata": {
        "id": "3GdglZjK04cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "127cf101-271d-4199-e8d6-2a5fdff76017"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to /data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 150420269.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to /data/mnist/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to /data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 45065362.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to /data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to /data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 214926079.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to /data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to /data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4602688.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to /data/mnist/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Define a transform\n",
        "transform = transforms.Compose([\n",
        "            transforms.Resize((28, 28)),\n",
        "            transforms.Grayscale(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize((0,), (1,))])\n",
        "\n",
        "mnist_train = datasets.MNIST(data_path, train=True, download=True, transform=transform)\n",
        "mnist_test = datasets.MNIST(data_path, train=False, download=True, transform=transform)\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BtJBOtez11wy",
      "metadata": {
        "id": "BtJBOtez11wy"
      },
      "source": [
        "## Define Network with snnTorch.\n",
        "* `snn.Leaky()` instantiates a simple leaky integrate-and-fire (LIF_ neuron.\n",
        "* `spike_grad` optionally defines the surrogate gradient. Defaults to the arctangent surrogate gradient.\n",
        "\n",
        "By default, each LIF neuron returns two values: the spike and hidden state.\n",
        "But neurons chained together in `nn.Sequential` expect only one value. To handle this:\n",
        "\n",
        "* `init_hidden` initializes the hidden states (e.g., membrane potential) as instance variables to be processed in the background.\n",
        "\n",
        "The final layer is not bound by this constraint, and can return multiple tensors:\n",
        "* `output=True` enables the final layer to return the hidden state in addition to the spike."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "JM2thnrc10rD",
      "metadata": {
        "id": "JM2thnrc10rD"
      },
      "outputs": [],
      "source": [
        "from snntorch import surrogate\n",
        "\n",
        "beta = 0.9  # neuron decay rate\n",
        "spike_grad = surrogate.fast_sigmoid() # fast sigmoid surrogate gradient\n",
        "\n",
        "#  Initialize Convolutional SNN\n",
        "net = nn.Sequential(nn.Conv2d(1, 8, 5),\n",
        "                    nn.MaxPool2d(2),\n",
        "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n",
        "                    nn.Conv2d(8, 16, 5),\n",
        "                    nn.MaxPool2d(2),\n",
        "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True),\n",
        "                    nn.Flatten(),\n",
        "                    nn.Linear(16*4*4, 10),\n",
        "                    snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, output=True)\n",
        "                    ).to(device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#change to keras Sequential\n",
        "from tensorflow.keras.models import Sequential\n",
        "import tensorflow.keras.layers as klayers\n",
        "#import Conv1D, BatchNormalization, MaxPool1D, Dropout, Flatten, Dense\n",
        "net = Sequential()\n"
      ],
      "metadata": {
        "id": "wmH3OCr_s4Nu"
      },
      "id": "wmH3OCr_s4Nu",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net.add (klayers.Conv2D(1, 8, 5))\n",
        "net.add(klayers.MaxPooling2D(2))\n",
        "net.add(snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True))\n",
        "net.add(nn.Conv2d(8, 16, 5))\n",
        "net.add(klayers.MaxPooling2D(2))\n",
        "net.add(snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True))\n",
        "net.add(klayers.Flatten())\n",
        "net.add(klayers.Linear(16*4*4, 10))\n",
        "net.add(snn.Leaky(beta=beta, spike_grad=spike_grad, init_hidden=True, output=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "z5C6YUuDCihX",
        "outputId": "308713d2-d2da-47bc-fbac-59ff68f82847"
      },
      "id": "z5C6YUuDCihX",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-9c2319adf10a>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mklayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLeaky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbeta\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspike_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspike_grad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minit_hidden\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mklayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/trackable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    183\u001b[0m                 \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m             raise TypeError(\n\u001b[0m\u001b[1;32m    186\u001b[0m                 \u001b[0;34m\"The added layer must be an instance of class Layer. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                 \u001b[0;34mf\"Received: layer={layer} of type {type(layer)}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: The added layer must be an instance of class Layer. Received: layer=Leaky() of type <class 'snntorch._neurons.leaky.Leaky'>."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(net)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "lLlOsarKson1",
        "outputId": "092c9fdb-96ce-4ad9-9ece-d00fc155453c"
      },
      "id": "lLlOsarKson1",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-8c4c62d57d93>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, dpi, layer_range, show_layer_activations, show_trainable)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \"\"\"\n\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m         raise ValueError(\n\u001b[1;32m    446\u001b[0m             \u001b[0;34m\"This model has not yet been built. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1613\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1614\u001b[0;31m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0m\u001b[1;32m   1615\u001b[0m             type(self).__name__, name))\n\u001b[1;32m   1616\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Sequential' object has no attribute 'built'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "tYSy5UuP4gXL",
      "metadata": {
        "id": "tYSy5UuP4gXL"
      },
      "source": [
        "Refer to the snnTorch documentation to see more [neuron types](https://snntorch.readthedocs.io/en/latest/snntorch.html) and [surrogate gradient options](https://snntorch.readthedocs.io/en/latest/snntorch.surrogate.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sIrJnBoz490c",
      "metadata": {
        "id": "sIrJnBoz490c"
      },
      "source": [
        "## Define the Forward Pass\n",
        "Now define the forward pass over multiple time steps of simulation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "hWa8f_We4-8z",
      "metadata": {
        "id": "hWa8f_We4-8z"
      },
      "outputs": [],
      "source": [
        "from snntorch import utils\n",
        "\n",
        "def forward_pass(net, data, num_steps):\n",
        "  spk_rec = [] # record spikes over time\n",
        "  utils.reset(net)  # reset/initialize hidden states for all LIF neurons in net\n",
        "\n",
        "  for step in range(num_steps): # loop over time\n",
        "      spk_out, mem_out = net(data) # one time step of the forward-pass\n",
        "      spk_rec.append(spk_out) # record spikes\n",
        "\n",
        "  return torch.stack(spk_rec)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9nGhh2_25NU8",
      "metadata": {
        "id": "9nGhh2_25NU8"
      },
      "source": [
        "Define the optimizer and loss function. Here, we use the MSE Count Loss, which counts up the total number of output spikes at the end of the simulation run. The correct class has a target firing rate of 80% of all time steps, and incorrect classes are set to 20%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "VocYbtD7Vwp7",
      "metadata": {
        "id": "VocYbtD7Vwp7"
      },
      "outputs": [],
      "source": [
        "import snntorch.functional as SF\n",
        "\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=2e-3, betas=(0.9, 0.999))\n",
        "loss_fn = SF.mse_count_loss(correct_rate=0.8, incorrect_rate=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "CWkx4ll761gU",
      "metadata": {
        "id": "CWkx4ll761gU"
      },
      "source": [
        "Objective functions do not have to be applied to the spike count. They may be applied to the membrane potential (hidden state), or to spike-timing targets instead of rate-based methods. A non-exhaustive list of objective functions available include:\n",
        "\n",
        "**Apply the objective directly to spikes:**\n",
        "* MSE Spike Count Loss: `mse_count_loss()`\n",
        "* Cross Entropy Spike Count Loss: `ce_count_loss()`\n",
        "* Cross Entropy Spike Rate Loss: `ce_rate_loss()`\n",
        "\n",
        "**Apply the objective to the hidden state:**\n",
        "* Cross Entropy Maximum Membrane Potential Loss: `ce_max_membrane_loss()`\n",
        "* MSE Membrane Potential Loss: `mse_membrane_loss()`\n",
        "\n",
        "For alternative objective functions, refer to the `snntorch.functional` [documentation here.](https://snntorch.readthedocs.io/en/latest/snntorch.functional.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48_7sIT86iUJ",
      "metadata": {
        "id": "48_7sIT86iUJ"
      },
      "source": [
        "## Training Loop\n",
        "\n",
        "Now for the training loop. The predicted class will be set to the neuron with the highest firing rate, i.e., a rate-coded output. We will just measure accuracy on the training set. This training loop follows the same syntax as with PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "kGZf7Hr55psl",
      "metadata": {
        "id": "kGZf7Hr55psl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "759d3e26-9bb9-4a34-df8e-1a4ca4f80ceb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Iteration 0 \n",
            "Train Loss: 2.46\n",
            "Accuracy: 13.28%\n",
            "\n",
            "Epoch 0, Iteration 25 \n",
            "Train Loss: 0.67\n",
            "Accuracy: 48.44%\n",
            "\n",
            "Epoch 0, Iteration 50 \n",
            "Train Loss: 0.49\n",
            "Accuracy: 69.53%\n",
            "\n",
            "Epoch 0, Iteration 75 \n",
            "Train Loss: 0.41\n",
            "Accuracy: 79.69%\n",
            "\n",
            "Epoch 0, Iteration 100 \n",
            "Train Loss: 0.32\n",
            "Accuracy: 92.19%\n",
            "\n",
            "Epoch 0, Iteration 125 \n",
            "Train Loss: 0.30\n",
            "Accuracy: 91.41%\n",
            "\n",
            "Epoch 0, Iteration 150 \n",
            "Train Loss: 0.26\n",
            "Accuracy: 95.31%\n",
            "\n",
            "Epoch 0, Iteration 175 \n",
            "Train Loss: 0.23\n",
            "Accuracy: 92.19%\n",
            "\n",
            "Epoch 0, Iteration 200 \n",
            "Train Loss: 0.23\n",
            "Accuracy: 93.75%\n",
            "\n",
            "Epoch 0, Iteration 225 \n",
            "Train Loss: 0.21\n",
            "Accuracy: 96.09%\n",
            "\n",
            "Epoch 0, Iteration 250 \n",
            "Train Loss: 0.20\n",
            "Accuracy: 95.31%\n",
            "\n",
            "Epoch 0, Iteration 275 \n",
            "Train Loss: 0.20\n",
            "Accuracy: 96.09%\n",
            "\n",
            "Epoch 0, Iteration 300 \n",
            "Train Loss: 0.18\n",
            "Accuracy: 96.88%\n",
            "\n",
            "Epoch 0, Iteration 325 \n",
            "Train Loss: 0.19\n",
            "Accuracy: 95.31%\n",
            "\n",
            "Epoch 0, Iteration 350 \n",
            "Train Loss: 0.19\n",
            "Accuracy: 96.88%\n",
            "\n",
            "Epoch 0, Iteration 375 \n",
            "Train Loss: 0.16\n",
            "Accuracy: 97.66%\n",
            "\n",
            "Epoch 0, Iteration 400 \n",
            "Train Loss: 0.17\n",
            "Accuracy: 95.31%\n",
            "\n",
            "Epoch 0, Iteration 425 \n",
            "Train Loss: 0.17\n",
            "Accuracy: 94.53%\n",
            "\n",
            "Epoch 0, Iteration 450 \n",
            "Train Loss: 0.15\n",
            "Accuracy: 97.66%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "num_epochs = 1 # run for 1 epoch - each data sample is seen only once\n",
        "num_steps = 25  # run for 25 time steps\n",
        "\n",
        "loss_hist = [] # record loss over iterations\n",
        "acc_hist = [] # record accuracy over iterations\n",
        "\n",
        "# training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (data, targets) in enumerate(iter(train_loader)):\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        net.train()\n",
        "        spk_rec = forward_pass(net, data, num_steps) # forward-pass\n",
        "        loss_val = loss_fn(spk_rec, targets) # loss calculation\n",
        "        optimizer.zero_grad() # null gradients\n",
        "        loss_val.backward() # calculate gradients\n",
        "        optimizer.step() # update weights\n",
        "        loss_hist.append(loss_val.item()) # store loss\n",
        "\n",
        "        # print every 25 iterations\n",
        "        if i % 25 == 0:\n",
        "          print(f\"Epoch {epoch}, Iteration {i} \\nTrain Loss: {loss_val.item():.2f}\")\n",
        "\n",
        "          # check accuracy on a single batch\n",
        "          acc = SF.accuracy_rate(spk_rec, targets)\n",
        "          acc_hist.append(acc)\n",
        "          print(f\"Accuracy: {acc * 100:.2f}%\\n\")\n",
        "\n",
        "        # uncomment for faster termination\n",
        "        # if i == 150:\n",
        "        #     break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "mjOR18HA77gc",
      "metadata": {
        "id": "mjOR18HA77gc"
      },
      "source": [
        "## More control over your model\n",
        "If you are simulating more complex architectures, such as residual nets, then your best bet is to wrap the network up in a class as shown below. This time, we will explicitly use the membrane potential, `mem`, and let `init_hidden` default to false.\n",
        "\n",
        "For the sake of speed, we'll just simulate a fully-connected SNN, but this can be generalized to other network types (e.g., Convs).\n",
        "\n",
        "In addition, let's set the neuron decay rate, `beta`, to be a learnable parameter. The first layer will have a shared decay rate across neurons. Each neuron in the second layer will have an independent decay rate. The decay is clipped between [0,1]."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "7d286ef9-5fe6-4578-a686-91559a1f81d2",
      "metadata": {
        "id": "7d286ef9-5fe6-4578-a686-91559a1f81d2"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# Define Network\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        num_inputs = 784 # number of inputs\n",
        "        num_hidden = 300 # number of hidden neurons\n",
        "        num_outputs = 10 # number of classes (i.e., output neurons)\n",
        "\n",
        "        beta1 = 0.9 # global decay rate for all leaky neurons in layer 1\n",
        "        beta2 = torch.rand((num_outputs), dtype = torch.float) # independent decay rate for each leaky neuron in layer 2: [0, 1)\n",
        "\n",
        "        # Initialize layers\n",
        "        self.fc1 = nn.Linear(num_inputs, num_hidden)\n",
        "        self.lif1 = snn.Leaky(beta=beta1) # not a learnable decay rate\n",
        "        self.fc2 = nn.Linear(num_hidden, num_outputs)\n",
        "        self.lif2 = snn.Leaky(beta=beta2, learn_beta=True) # learnable decay rate\n",
        "\n",
        "    def forward(self, x):\n",
        "        mem1 = self.lif1.init_leaky() # reset/init hidden states at t=0\n",
        "        mem2 = self.lif2.init_leaky() # reset/init hidden states at t=0\n",
        "        spk2_rec = [] # record output spikes\n",
        "        mem2_rec = [] # record output hidden states\n",
        "\n",
        "        for step in range(num_steps): # loop over time\n",
        "            cur1 = self.fc1(x.flatten(1))\n",
        "            spk1, mem1 = self.lif1(cur1, mem1)\n",
        "            cur2 = self.fc2(spk1)\n",
        "            spk2, mem2 = self.lif2(cur2, mem2)\n",
        "\n",
        "            spk2_rec.append(spk2) # record spikes\n",
        "            mem2_rec.append(mem2) # record membrane\n",
        "\n",
        "        return torch.stack(spk2_rec), torch.stack(mem2_rec)\n",
        "\n",
        "# Load the network onto CUDA if available\n",
        "net = Net().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "_aCrVAh_cyTU",
      "metadata": {
        "id": "_aCrVAh_cyTU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a68a54f7-255d-41c1-c199-ebda35ed2a09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Iteration 0 \n",
            "Train Loss: 2.50\n",
            "Accuracy: 5.47%\n",
            "\n",
            "Epoch 0, Iteration 25 \n",
            "Train Loss: 0.65\n",
            "Accuracy: 66.41%\n",
            "\n",
            "Epoch 0, Iteration 50 \n",
            "Train Loss: 0.38\n",
            "Accuracy: 83.59%\n",
            "\n",
            "Epoch 0, Iteration 75 \n",
            "Train Loss: 0.32\n",
            "Accuracy: 88.28%\n",
            "\n",
            "Epoch 0, Iteration 100 \n",
            "Train Loss: 0.29\n",
            "Accuracy: 91.41%\n",
            "\n",
            "Epoch 0, Iteration 125 \n",
            "Train Loss: 0.27\n",
            "Accuracy: 90.62%\n",
            "\n",
            "Epoch 0, Iteration 150 \n",
            "Train Loss: 0.19\n",
            "Accuracy: 96.09%\n",
            "\n",
            "Epoch 0, Iteration 175 \n",
            "Train Loss: 0.19\n",
            "Accuracy: 96.09%\n",
            "\n",
            "Epoch 0, Iteration 200 \n",
            "Train Loss: 0.21\n",
            "Accuracy: 92.97%\n",
            "\n",
            "Epoch 0, Iteration 225 \n",
            "Train Loss: 0.20\n",
            "Accuracy: 92.19%\n",
            "\n",
            "Epoch 0, Iteration 250 \n",
            "Train Loss: 0.22\n",
            "Accuracy: 91.41%\n",
            "\n",
            "Epoch 0, Iteration 275 \n",
            "Train Loss: 0.16\n",
            "Accuracy: 95.31%\n",
            "\n",
            "Epoch 0, Iteration 300 \n",
            "Train Loss: 0.17\n",
            "Accuracy: 91.41%\n",
            "\n",
            "Epoch 0, Iteration 325 \n",
            "Train Loss: 0.16\n",
            "Accuracy: 96.88%\n",
            "\n",
            "Epoch 0, Iteration 350 \n",
            "Train Loss: 0.15\n",
            "Accuracy: 95.31%\n",
            "\n",
            "Epoch 0, Iteration 375 \n",
            "Train Loss: 0.13\n",
            "Accuracy: 96.88%\n",
            "\n",
            "Epoch 0, Iteration 400 \n",
            "Train Loss: 0.18\n",
            "Accuracy: 92.19%\n",
            "\n",
            "Epoch 0, Iteration 425 \n",
            "Train Loss: 0.15\n",
            "Accuracy: 96.88%\n",
            "\n",
            "Epoch 0, Iteration 450 \n",
            "Train Loss: 0.15\n",
            "Accuracy: 91.41%\n",
            "\n"
          ]
        }
      ],
      "source": [
        "optimizer = torch.optim.Adam(net.parameters(), lr=2e-3, betas=(0.9, 0.999))\n",
        "loss_fn = SF.mse_count_loss(correct_rate=0.8, incorrect_rate=0.2)\n",
        "\n",
        "num_epochs = 1 # run for 1 epoch - each data sample is seen only once\n",
        "num_steps = 25  # run for 25 time steps\n",
        "\n",
        "loss_hist = [] # record loss over iterations\n",
        "acc_hist = [] # record accuracy over iterations\n",
        "\n",
        "# training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (data, targets) in enumerate(iter(train_loader)):\n",
        "        data = data.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        net.train()\n",
        "        spk_rec, _ = net(data) # forward-pass\n",
        "        loss_val = loss_fn(spk_rec, targets) # loss calculation\n",
        "        optimizer.zero_grad() # null gradients\n",
        "        loss_val.backward() # calculate gradients\n",
        "        optimizer.step() # update weights\n",
        "        loss_hist.append(loss_val.item()) # store loss\n",
        "\n",
        "        # print every 25 iterations\n",
        "        if i % 25 == 0:\n",
        "          net.eval()\n",
        "          print(f\"Epoch {epoch}, Iteration {i} \\nTrain Loss: {loss_val.item():.2f}\")\n",
        "\n",
        "          # check accuracy on a single batch\n",
        "          acc = SF.accuracy_rate(spk_rec, targets)\n",
        "          acc_hist.append(acc)\n",
        "          print(f\"Accuracy: {acc * 100:.2f}%\\n\")\n",
        "\n",
        "        # uncomment for faster termination\n",
        "        # if i == 150:\n",
        "        #     break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "hmZJRdzIgpMb",
      "metadata": {
        "id": "hmZJRdzIgpMb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d13fd59f-9f79-45b0-dd8f-afc61d5c2daf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trained decay rate of the first layer: 0.900\n",
            "\n",
            "Trained decay rates of the second layer: Parameter containing:\n",
            "tensor([0.3755, 0.8418, 0.8349, 0.4083, 0.8732, 0.2975, 0.3141, 0.3204, 0.5190,\n",
            "        0.8685], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Trained decay rate of the first layer: {net.lif1.beta:.3f}\\n\")\n",
        "\n",
        "print(f\"Trained decay rates of the second layer: {net.lif2.beta}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "CXCggOzk2vYF",
      "metadata": {
        "id": "CXCggOzk2vYF"
      },
      "outputs": [],
      "source": [
        "# function to measure accuracy on full test set\n",
        "def test_accuracy(data_loader, net, num_steps):\n",
        "  with torch.no_grad():\n",
        "    total = 0\n",
        "    acc = 0\n",
        "    net.eval()\n",
        "\n",
        "    data_loader = iter(data_loader)\n",
        "    for data, targets in data_loader:\n",
        "      data = data.to(device)\n",
        "      targets = targets.to(device)\n",
        "      spk_rec, _ = net(data)\n",
        "\n",
        "      acc += SF.accuracy_rate(spk_rec, targets) * spk_rec.size(1)\n",
        "      total += spk_rec.size(1)\n",
        "\n",
        "  return acc/total"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "ias_TerdCMoG",
      "metadata": {
        "id": "ias_TerdCMoG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98f3bca7-8d6d-468e-b00c-9123f694191c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set accuracy: 95.100%\n"
          ]
        }
      ],
      "source": [
        "print(f\"Test set accuracy: {test_accuracy(test_loader, net, num_steps)*100:.3f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "-iSGTq0Q3Lcm",
      "metadata": {
        "id": "-iSGTq0Q3Lcm"
      },
      "source": [
        "# Conclusion\n",
        "That's it for the quick intro to snnTorch!\n",
        "\n",
        "* For a detailed tutorial of spiking neurons, neural nets, encoding, and training using neuromorphic datasets, check out the\n",
        "[snnTorch tutorial series](https://snntorch.readthedocs.io/en/latest/tutorials/index.html).\n",
        "* For more information on the features of snnTorch, check out the [documentation at this link](https://snntorch.readthedocs.io/en/latest/).\n",
        "* If you have ideas, suggestions or would like to find ways to get involved, then [check out the snnTorch GitHub project here.](https://github.com/jeshraghian/snntorch)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "c8b87b4648a8d1ba1118329c37c7c28a2ff48490805f0e62ea19d4b1b49e5656"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}